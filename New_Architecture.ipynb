{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's import various packages that we need\n",
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "import dataset\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to training images \n",
    "train_path = \"../../pimed/pimed_tutorials/python/data/write/rot_images_new_train/\"\n",
    "#data = dataset.read_train_sets(train_path, img_size, classes, validation_size=validation_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read data into an array\n",
    "from PIL import Image\n",
    "import os\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = Image.open(os.path.join(folder,filename))\n",
    "        A=np.asarray(img)\n",
    "        images.append(A)\n",
    "    return images\n",
    "images = load_images_from_folder(train_path)\n",
    "images = np.array(images)\n",
    "# print(len(images[0]))\n",
    "# filename = os.listdir(train_path)[0]\n",
    "# img = Image.open(os.path.join(train_path, filename))\n",
    "# print(img)\n",
    "# import numpy as np\n",
    "# A=np.asarray(img)\n",
    "# print(A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(495, 165, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-45b6126c5a59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# to see if read correctly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m '''\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m '''\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# read the labels\n",
    "label_path = '../../pimed/pimed_tutorials/python/data/labels/new_lab.txt'\n",
    "f = open(label_path, \"r\")\n",
    "data =[]\n",
    "for line in f:\n",
    "    data.append(line)\n",
    "# to see if read correctly    \n",
    "'''\n",
    "for i in data:\n",
    "    print(i)\n",
    "'''\n",
    "x = np.shape(data)[0]\n",
    "data = np.array(data)\n",
    "data = data.reshape(x,1)\n",
    "print(np.shape(data))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some test code to may print out a part of what we loaded\n",
    "## TO-DO: Look into the logic for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the input data as we read in 8 bit pixel values. We wish to convert them to some number between 0 and 1\n",
    "# Also encode the angles using one-hot encoding\n",
    "#X_train, X_test, Y_train, Y_test: X_train and X_test will be 4D tensors with (no. of examples, l,w, channels).\n",
    "# Y_train and Y_test: \n",
    "\n",
    "# uncomment this code later\n",
    "#print(\"Shape of X_train: \" + str(X_train.shape))\n",
    "#print(\"Shape of Y_train: \" + str(Y_train.shape))\n",
    "#print(\"Shape of X_test: \" + str(X_test.shape))\n",
    "#print(\"Shape of Y_test: \" + str(Y_test.shape))\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(495, 5)\n"
     ]
    }
   ],
   "source": [
    "# code that reads labels from a file and converts them to categorical\n",
    "# training labels\n",
    "label_path = \"../../pimed/pimed_tutorials/python/data/labels/iter_train.txt\" # insert path here\n",
    "num_cat = 5 # for now it's 5 categories\n",
    "f = open(label_path, \"r\") # open the file to read\n",
    "labels=[]\n",
    "#read all the labels and append them to this list\n",
    "for line in f:\n",
    "    labels.append(int(line)) # read as char, need to convert to int\n",
    "\n",
    "# let's print them out\n",
    "'''\n",
    "for i in range(len(labels)):\n",
    "    print(labels[i])\n",
    "'''\n",
    "\n",
    "# let's now convert them to categorical\n",
    "y = np.zeros((num_cat,len(labels)))\n",
    "\n",
    "# Logic for one-hot encoding\n",
    "for i in range(len(labels)):\n",
    "    if(labels[i]==-30):\n",
    "        y[0,i] = 1\n",
    "    elif(labels[i]==-15):\n",
    "        y[1,i] = 1\n",
    "    elif(labels[i]==0):\n",
    "        y[2,i] = 1\n",
    "    elif(labels[i]==15):\n",
    "        y[3,i] = 1\n",
    "    elif(labels[i]==30):\n",
    "        y[4,i] = 1\n",
    "y = np.transpose(y)\n",
    "print(np.shape(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create place holders for variables\n",
    "def create_placeholders(n_h,n_w,n_c,n_y):\n",
    "    '''\n",
    "    create place holders that will be used for building the graph. (X,Y)\n",
    "    h: height of the image\n",
    "    w: width of the image\n",
    "    c: number of channels in the image\n",
    "    y: number of output classes\n",
    "    '''\n",
    "    X = tf.placeholder(tf.float32, shape=(None,n_h,n_w,n_c)) # none is for the batch size and all\n",
    "    Y = tf.placeholder(tf.float32, shape=(None, n_y))\n",
    "    return X,Y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_parameters():\n",
    "    '''\n",
    "    Let's first accumulate all the Weights. Pool will be taken care of in the later section\n",
    "    '''\n",
    "    W1 = tf.get_variable(\"W1\", [3,3,3,64], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    W2 = tf.get_variable(\"W2\", [3,3,64,64], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    ## POOL COMES HERE IN THE ARCH\n",
    "    W3 = tf.get_variable(\"W3\", [3,3,64,128], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    W4 = tf.get_variable(\"W4\", [3,3,128,128], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    ''' WIll add these in later\n",
    "    ## POOL\n",
    "    W5 = tf.get_variable(\"W5\", [3,3,128,256], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    W6 = tf.get_variable(\"W6\", [3,3,256,256], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    W7 = tf.get_variable(\"W7\", [3,3,256,256], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    ## POOL\n",
    "    W8 = tf.get_variable(\"W8\", [3,3,256,512], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    W9 = tf.get_variable(\"W9\", [3,3,512,512], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    W10 = tf.get_variable(\"W10\", [3,3,512,512], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    ## POOL\n",
    "    W11 = tf.get_variable(\"W11\", [3,3,512,512], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    W12 = tf.get_variable(\"W12\", [3,3,512,512], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    W13 = tf.get_variable(\"W13\", [3,3,512,512], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    ## POOL \n",
    "    '''\n",
    "    # create a dictionary\n",
    "    parameters={\"W1\":W1, \"W2\":W2, \"W3\":W3, \"W4\":W4}\n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(X, parameters, n_classes, keep_prob):\n",
    "    '''\n",
    "    We passed the input and the dictionary that contains all the parameters\n",
    "    '''\n",
    "    # extract parameters from the dictionary\n",
    "    W1 = parameters[\"W1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    W3 = parameters[\"W3\"]\n",
    "    W4 = parameters[\"W4\"]\n",
    "    # Adding batch Norm\n",
    "    #X = tf.layers.batch_normalization(X, training=True)\n",
    "    \n",
    "    # the neural net part\n",
    "    Z1 = tf.nn.conv2d(X, W1, strides=[1,1,1,1], padding='SAME') # same convolutions\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    P1 = A1#tf.nn.max_pool(A1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    \n",
    "    Z2 = tf.nn.conv2d(P1, W2, strides=[1,1,1,1], padding='SAME')\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    P2 = tf.nn.max_pool(A2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    P2 = tf.nn.dropout(P2, keep_prob)  # DROP-OUT here\n",
    "    \n",
    "    Z3 = tf.nn.conv2d(P2, W3, strides=[1,1,1,1], padding='SAME')\n",
    "    A3 = tf.nn.relu(Z3)\n",
    "    P3 = A3#tf.nn.max_pool(A3, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    \n",
    "    Z4 = tf.nn.conv2d(P3, W4, strides=[1,1,1,1], padding='SAME')\n",
    "    A4 = tf.nn.relu(Z4)\n",
    "    P4 = tf.nn.max_pool(A4, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    \n",
    "    # let's now flatten the pool layers\n",
    "    P4 = tf.contrib.layers.flatten(P4)\n",
    "    \n",
    "    # Now connect to fully connected stuff\n",
    "    Z5 = tf.contrib.layers.fully_connected(P4, n_classes, activation_fn=None)\n",
    "    return Z5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z3 = [[-0.3316269   0.18119879 -0.95048463 -1.2105908   0.3677706 ]\n",
      " [-0.15386146 -0.12816648 -0.8777418  -0.9120508   0.45201078]]\n",
      "(?, 5)\n"
     ]
    }
   ],
   "source": [
    "# code to test if above thing works\n",
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    np.random.seed(1)\n",
    "    X, Y = create_placeholders(64, 64, 3, 5)\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    parameters = init_parameters()\n",
    "    #keep_probs = tf.placeholder(tf.float32) # probability from dropput\n",
    "    Z3 = forward_prop(X, parameters, 5, keep_prob)\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    a = sess.run(Z3, {X: np.random.randn(2,64,64,3), Y: np.random.randn(2,5), keep_prob:0.25})\n",
    "    print(\"Z3 = \" + str(a))\n",
    "    print(np.shape(Z3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass NN output and the ground truth\n",
    "# we will be using the cross entropy loss here\n",
    "def compute_cost(Z3, Y):\n",
    "    # applies softmax here\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=Z3, labels=Y))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 165, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "# Select a particular minibatch\n",
    "def get_mini_batches(X, Y, minibatch_size, seed):\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.choice(np.shape(X)[0], minibatch_size, replace=False)\n",
    "    Y_batch = Y[indices,:]\n",
    "    X_batch = X[indices,:,:,:]\n",
    "    return X_batch, Y_batch\n",
    "f,g = get_mini_batches(images, y, 3, 1)\n",
    "print(np.shape(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's build the model now\n",
    "def model(X_train, Y_train, X_test, Y_test, learning_rate=0.01,\n",
    "          num_epochs=10, minibatch_size=10, print_cost=True): \n",
    "    ''' Implements a three-layer ConvNet in Tensorflow: CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED\n",
    "    X_train -- training set, of shape (None, x,y,z)\n",
    "    Y_train -- test set, of shape (None, n_y = 5) 5 for now\n",
    "    X_test -- training set, of shape (None, x,y,z)\n",
    "    Y_test -- test set, of shape (None, n_y = 5)\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of a minibatch\n",
    "\n",
    "    Returns:\n",
    "    train_accuracy -- real number, accuracy on the train set (X_train)\n",
    "    test_accuracy -- real number, testing accuracy on the test set (X_test)\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    '''\n",
    "\n",
    "    ops.reset_default_graph() # so that we can run this multiple times. removes some error\n",
    "    tf.set_random_seed(1)\n",
    "    seed=3\n",
    "    (m,n_h,n_w,n_c) = np.shape(X_train) # height, width, number of channels\n",
    "    n_y = np.shape(Y_train)[1] # number of output classes\n",
    "    costs=[] # to store all the costs\n",
    "\n",
    "    #creating place holders\n",
    "    #X, Y = create_placeholders(n_h,n_w,n_c,n_y)\n",
    "    X = tf.placeholder(tf.float32, shape=(None,n_h,n_w,n_c))\n",
    "    Y = tf.placeholder(tf.float32, shape=(None,n_y))\n",
    "    #initializing parameters\n",
    "    parameters = init_parameters()\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    #Build computational graph\n",
    "    Z3 = forward_prop(X, parameters, n_y, keep_prob)\n",
    "    #Z3 = np.transpose(Z3) #commented out this line\n",
    "    #A3 = tf.nn.softmax(Z3)\n",
    "    #extend the graph to compute the graph\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    # select an optimizer\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    \n",
    "    #initialize global variables in the graph\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init) # run this session\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            \n",
    "            minibatch_cost=0\n",
    "            num_minibatches = int(m/minibatch_size)\n",
    "            seed = seed * 2 + 3 # change seed so that more random samples are picked from data\n",
    "            \n",
    "            for minibatch in range(1,num_minibatches):\n",
    "                minibatch_X, minibatch_Y = get_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "                seed = seed + 1\n",
    "                # get a mini-batch\n",
    "                #(minibatch_X, minibatch_Y) = minibatch\n",
    "                # compute total cost\n",
    "                _, temp_cost = sess.run([optimizer, cost], feed_dict={X:minibatch_X, Y:minibatch_Y, keep_prob:1})\n",
    "                minibatch_cost = temp_cost#/num_minibatches\n",
    "                \n",
    "                # let's now decide how to print the cost\n",
    "                if(print_cost==True and epoch%2==0):\n",
    "                    print(\"Cost after epoch: %i: %f\" %(epoch, minibatch_cost))\n",
    "                if(print_cost==True):\n",
    "                    costs.append(minibatch_cost)\n",
    "        \n",
    "        # that completes the model part\n",
    "        plt.plot(np.squeeze(costs)) # convert to array\n",
    "        plt.ylabel(\"cost\")\n",
    "        plt.xlabel(\"iteration (per 10s)\")\n",
    "        plt.title(\"Learning rate= \" + str(learning_rate))\n",
    "        plt.show()\n",
    "        \n",
    "        # let's now use the trained models to make predictions\n",
    "        predict_op = tf.argmax(Z3,1) #returns index\n",
    "        ground_th = tf.argmax(Y,1)\n",
    "        #prediction=tf.argmax(y,1)\n",
    "        # printing the predictions\n",
    "        \n",
    "        print predict_op.eval(feed_dict={X: X_test, keep_prob:1})\n",
    "        print ground_th.eval(feed_dict={Y: Y_test, keep_prob:1})\n",
    "        correct_prediction = tf.equal(predict_op, tf.argmax(Y,1))\n",
    "        \n",
    "        \n",
    "        #let's now calculate the cost\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        #print(accuracy)\n",
    "        train_accuracy =  accuracy.eval({X:X_train, Y:Y_train, keep_prob:1})\n",
    "        test_accuracy = accuracy.eval({X:X_test, Y:Y_test, keep_prob:1})\n",
    "        print(\"Train Accuracy: \", train_accuracy)\n",
    "        print(\"Test Accuracy: \", test_accuracy)\n",
    "        print(\"Learning rate:\", learning_rate)\n",
    "        print(\"Number of Epochs:\", num_epochs)\n",
    "        print(\"Mini-batch Size:\", minibatch_size)\n",
    "        return train_accuracy, test_accuracy, parameters, predict_op\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 5)\n"
     ]
    }
   ],
   "source": [
    "#let's test data and see how the network performs\n",
    "# code that reads labels from a file and converts them to categorical\n",
    "test_path = \"../../pimed/pimed_tutorials/python/data/labels/iter_test.txt\" # insert path here\n",
    "num_cat = 5 # for now it's 5 categories\n",
    "f = open(test_path, \"r\") # open the file to read\n",
    "test_labels=[]\n",
    "#read all the labels and append them to this list\n",
    "for line in f:\n",
    "    test_labels.append(int(line)) # read as char, need to convert to int\n",
    "\n",
    "# let's print them out\n",
    "'''\n",
    "for i in range(len(test_labels)):\n",
    "    print(test_labels[i])\n",
    "'''\n",
    "\n",
    "# let's now convert them to categorical\n",
    "Y_test = np.zeros((num_cat,len(test_labels)))\n",
    "\n",
    "#encoding\n",
    "for i in range(len(test_labels)):\n",
    "    if(test_labels[i]==-30):\n",
    "        Y_test[0,i] = 1\n",
    "    elif(test_labels[i]==-15):\n",
    "        Y_test[1,i] = 1\n",
    "    elif(test_labels[i]==0):\n",
    "        Y_test[2,i] = 1\n",
    "    elif(test_labels[i]==15):\n",
    "        Y_test[3,i] = 1\n",
    "    elif(test_labels[i]==30):\n",
    "        Y_test[4,i] = 1\n",
    "Y_test = np.transpose(Y_test)\n",
    "print(np.shape(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 165, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "## Let's now read the images\n",
    "test_im_path = \"../../pimed/pimed_tutorials/python/data/write/rot_images_new_test/\"\n",
    "X_test = load_images_from_folder(test_im_path)\n",
    "X_test = np.array(X_test)\n",
    "print(np.shape(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch: 0: 8.893380\n",
      "Cost after epoch: 0: 151998.546875\n",
      "Cost after epoch: 0: 596.103210\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 2 4 4 4 4 4 4 4 4 4 4]\n",
      "[0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1\n",
      " 2 3 4 0 1 2 3 4 0 1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "_, _, parameters, predict_op = model(images, y, X_test, Y_test, learning_rate = 0.01,num_epochs=2, minibatch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
